## template 中 mapping 建立规则：

1、ES索引尽量不要存储非搜索字段，尽量通过主键在MySQL数据库中查询

2、ES索引中mapping审计字段类型中,精确查询中int、long、short类型统一改为keyword类型，提高索引搜索性能；需要分词就设置为 text；mysql 表中 column 是 number 类型字段，需要看 es 搜索方式，如果字段是范围查询，将此字段设为 number 类型，具体类型看上面链接，如果是精确查询（等于、in 操作），则设置为 keyword 类型。

3、ES索引中合理设置主分片以及副本分片，0--50G的索引建议一个主分片一个副本分片、50--100G建议2个主分片一个副本分片，可大大的提高搜索效率

4、ES索引中关于是否删除字段的存储，建议对已经逻辑删除的数据，及时从的ES索引中删除，提高搜索效率

5、确定字段是否只需要搜索，确定不需要排序、聚合、使用脚本的字段，使用"doc_values": false将其关闭

6、norms:用于在搜索时计算该doc的_score（代表这条数据与搜索条件的相关度），如果不需要评分，可以将其关闭



## 建立索引规范

### 1.index：控制倒排索引

ES默认对于所有字段都开启了倒排索引，用于查询。对于没有查询需求的字段，可以通过下面的命令关闭倒排索引。

### 2._all：ES的一个特殊的字段

ES把用户写入json的所有字段值拼接成一个字符串后，做分词，然后保存倒排索引，用于支持整个json的全文检索。这种需求适用的场景较少，可以通过下面的命令将\_all字段关闭，节约存储成本和cpu开销。（ES 6.0+以上的版本不再支持_all字段，不需要设置）

### 3.为string类型的字段选取合适的存储方式

精细设置全文域：string类型字段默认会分词，不仅会额外占用资源，而且会影响创建索引的速度。所以，把不需要分词的字段设置为not_analyzed。

  存为text类型的字段（string字段默认类型为text）： 做分词后存储倒排索引，支持模糊、精确查询，支持全文检索，不支持聚合。可以通过下面几个参数优化其存储方式： 

   norms：用于在搜索时计算该doc的_score（代表这条数据与搜索条件的相关度），如果不需要评分，可以将其关闭。 

   index_options：控制倒排索引中包括哪些信息（docs、freqs、positions、offsets）。对于不太注重_score/highlighting的使用场景，可以设为 docs来降低内存/磁盘资源消耗。

   fields: 用于添加子字段。对于有sort和聚合查询需求的场景，可以添加一个keyword子字段以支持这两种功能。

 存为keyword类型的字段： 不做分词，支持模糊、精确查询，支持聚合，不支持全文检索。text分词消耗CPU资源，冗余存储keyword子字段占用存储空间。如果没有全文索引需求，只是要通过整个字段做搜索，可以设置该字段的类型为keyword，提升写入速率，降低存储成本。 设置字段类型的方法有两种：一是创建一个具体的index时，指定字段的类型；二是通过创建template，控制某一类index的字段类型。

### 4.index按日期滚动，便于管理

写入ES的数据最好通过某种方式做分割，存入不同的index。常见的做法是将数据按模块/功能分类，写入不同的index，然后按照时间去滚动生成index。这样做的好处是各种数据分开管理不会混淆，也易于提高查询效率。同时index按时间滚动，数据过期时删除整个index，要比一条条删除数据或delete_by_query效率高很多，因为删除整个index是直接删除底层文件，而delete_by_query是查询-标记-删除。

举例说明，假如有module_a,moduleb两个模块产生的数据，那么index规划可以是这样的：一类index名称是module_a + {日期}，另一类index名称是module_b+ {日期}。对于名字中的日期，可以在写入数据时自己指定精确的日期，也可以通过ES的ingest pipeline中的[index-name-processor](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/date-index-name-processor.html)实现（会有写入性能损耗）。

### 5.按需控制index的分片数和副本数

分片（shard）：一个ES的index由多个shard组成，每个shard承载index的一部分数据。

副本（replica）：index也可以设定副本数（number_of_replicas），也就是同一个shard有多少个备份。对于查询压力较大的index，可以考虑提高副本数（number_of_replicas），通过多个副本均摊查询压力

shard数量（number_of_shards）设置过多或过低都会引发一些问题：shard数量过多，则批量写入/查询请求被分割为过多的子写入/查询，导致该index的写入、查询拒绝率上升，过度使用分片是一个over-sahrding，例如你数据量很少，用了多个分片。tf-idf算分会产生不准的情况。因为es会在每个分片上计算。而idf是一个全局的指标，数据量过少，算得肯定不对；对于数据量较大的inex，当其shard数量过小时，无法充分利用节点资源，造成机器资源利用率不高 或 不均衡，影响写入/查询的效率。

对于每个index的shard数量，可以根据数据总量、写入压力、节点数量等综合考量后设定，然后根据数据增长状态定期检测下shard数量是否合理。腾讯云CES技术团队的推荐方案是：

- 对于数据量较小（100GB以下）的index，往往写入压力查询压力相对较低，一般设置3~5个shard，number_of_replicas设置为1即可（也就是一主一从，共两副本） 。
- 对于数据量较大（100GB以上）的index： 		一般把单个shard的数据量控制在（20GB~50GB） 		让index压力分摊至多个节点：可通过index.routing.allocation.total_shards_per_node参数，强制限定一个节点上该index的shard数量，让shard尽量分配到不同节点上 		综合考虑整个index的shard数量，如果shard数量（不包括副本）超过50个，就很可能引发拒绝率上升的问题，此时可考虑把该index拆分为多个独立的index，分摊数据量，同时配合routing使用，降低每个查询需要访问的shard数量。

### 6.查询使用routing

对于数据量较大的index，一般会配置多个shard来分摊压力。这种场景下，一个查询会同时搜索所有的shard，然后再将各个shard的结果合并后，返回给用户。对于高并发的小查询场景，每个分片通常仅抓取极少量数据，此时查询过程中的调度开销远大于实际读取数据的开销，且查询速度取决于最慢的一个分片。开启routing功能后，ES会将routing相同的数据写入到同一个分片中（也可以是多个，由index.routing_partition_size参数控制）。如果查询时指定routing，那么ES只会查询routing指向的那个分片，可显著降低调度开销，提升查询效率。

### 7.调整refresh_interval

写入Lucene的数据，并不是实时可搜索的，ES必须通过refresh的过程把内存中的数据转换成Lucene的完整segment后，才可以被搜索。默认情况下，ES每一秒会refresh一次，产生一个新的segment，这样会导致产生的segment较多，从而segment merge较为频繁，系统开销较大。如果对数据的实时可见性要求较低，可以通过下面的命令提高refresh的时间间隔，降低系统开销。

​    由于在buffer中的索引片先同步到文件系统缓存，再刷写到磁盘，因此在检索时可以直接检索文件系统缓存，保证了实时性。这一步刷到文件系统缓存的步骤，在 Elasticsearch 中，是默认设置为 1 秒间隔的，对于大多数应用来说，几乎就相当于是实时可搜索了。不过对于 ELK 的日志场景来说，并不需要如此高的实时性，而是需要更快的写入性能。我们可以通过 /_settings 接口或者定制 template 的方式，加大 refresh_interval 参数。

### 8.es节点配置

#### 8.1 jam.options

-Xms和-Xmx设置为相同的值，推荐设置为机器内存的一半左右，剩余一半留给系统cache使用

jvm内存建议不要低于2G，否则有可能因为内存不足导致ES无法正常启动或OOM

Zjvm建议不要超过32G，否则jvm会禁用内存对象指针压缩技术，造成内存浪费

#### 8.2 elasticsearch.yml

设置内存熔断参数，防止写入或查询压力过高导致OOM，具体数值可根据使用场景调整。 indices.breaker.total.limit: 30%

indices.breaker.request.limit: 6%

indices.breaker.fielddata.limit: 3%

调小查询使用的cache，避免cache占用过多的jvm内存，具体数值可根据使用场景调整。 indices.queries.cache.count: 500 indices.queries.cache.size: 5%

- 